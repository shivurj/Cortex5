# Cortex5 AI Hedge Fund

An autonomous AI-powered hedge fund system built with LangGraph, Docker, and Kubernetes. Cortex5 employs a "Council of Agents" architecture where specialized AI agents collaborate to analyze market data, assess sentiment, and execute trades.

## ğŸ— Architecture

The system consists of 5 specialized agents orchestrated by a State Graph:

1.  **Data Agent**: Fetches OHLCV data from Yahoo Finance, validates it, and stores in TimescaleDB.
2.  **Sentiment Agent**: Performs RAG-based sentiment analysis using Qdrant vector search and LLM.
3.  **Quant Agent**: Performs technical analysis (RSI, MACD) with crossover detection.
4.  **Risk Agent**: Multi-factor validation (position size, volatility, sentiment, capital).
5.  **Execution Agent**: Logs approved trades to TimescaleDB.

### Tech Stack
-   **Orchestration**: LangGraph, LangChain
-   **LLM**: Ollama (Llama 3.2:3b)
-   **Databases**: 
    -   TimescaleDB (Time-series OHLCV data)
    -   Qdrant (Vector DB for news embeddings)
-   **Data Sources**: Yahoo Finance (market data), Google Finance RSS / NewsAPI (news)
-   **ML**: Sentence Transformers (BAAI/bge-small-en-v1.5)
-   **Infrastructure**: Docker Compose, Kubernetes (Kind)
-   **Language**: Python 3.10+

## âœ¨ Features

### Day 1: Foundation
- âœ… 5 AI agents with LangGraph orchestration
- âœ… Docker Compose infrastructure
- âœ… Kubernetes (Kind) local deployment
- âœ… Basic agent workflow

### Day 2: Intelligence & Data
- âœ… **Real Market Data**: Yahoo Finance integration with retry logic
- âœ… **Data Validation**: 7-layer OHLCV integrity checks
- âœ… **TimescaleDB**: Hypertables, continuous aggregates, connection pooling
- âœ… **News Ingestion**: Google Finance RSS + NewsAPI with caching
- âœ… **RAG Pipeline**: Sentence transformers + Qdrant vector search
- âœ… **Technical Analysis**: RSI, MACD, Bollinger Bands, volatility indicators
- âœ… **Risk Management**: Position limits, volatility checks, sentiment gates
- âœ… **Trade Logging**: Persistent storage with full audit trail

## ğŸš€ Getting Started

### Prerequisites
-   [Docker Desktop](https://www.docker.com/products/docker-desktop/)
-   [Python 3.10+](https://www.python.org/)
-   [Ollama](https://ollama.com/) (for local LLM inference)
-   Optional: [Kind](https://kind.sigs.k8s.io/) for Kubernetes testing

### 1. Clone the Repository
```bash
git clone https://github.com/shivurj/Cortex5.git
cd Cortex5
```

### 2. Configure Environment
Copy the example environment file and configure settings:

```bash
cp .env.example .env
```

Edit `.env` to configure:
- Database credentials (TimescaleDB)
- Qdrant connection
- NewsAPI key (optional - falls back to Google Finance RSS)
- Risk management parameters

### 3. Pull LLM Model
Ensure you have the Ollama model:
```bash
ollama pull llama3.2:3b
```

### 4. Start Infrastructure
Start the database services using Docker Compose:

```bash
docker-compose up -d
```

This starts:
- TimescaleDB (port 5432)
- Qdrant (port 6333)
- Ollama (port 11434)

### 5. Install Dependencies
Create a virtual environment and install dependencies:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
```

### 6. Initialize Database
Create the TimescaleDB schema (hypertables, indexes, functions):

```bash
python scripts/init_db.py
```

### 7. Ingest News Data (Optional)
Populate Qdrant with financial news for sentiment analysis:

```bash
python scripts/ingest_news.py --tickers AAPL,GOOGL,MSFT --days 7
```

### 8. Run the System
Execute the main script to analyze a ticker:

```bash
python main.py
```

The system will:
1. Fetch market data from Yahoo Finance
2. Analyze sentiment from news articles
3. Calculate technical indicators (RSI, MACD)
4. Validate trade against risk parameters
5. Log execution decision to database

## ğŸ“Š Usage Examples

### Analyze a Stock
```bash
python main.py  # Analyzes ticker from message (default: AAPL)
```

### Ingest News for Multiple Tickers
```bash
python scripts/ingest_news.py --tickers AAPL,GOOGL,MSFT,TSLA --days 14
```

### Initialize/Reset Database
```bash
python scripts/init_db.py
```

## â˜¸ï¸ Kubernetes Setup (Local)
To simulate production deployment using Kind:

1.  **Setup Cluster**:
    ```bash
    ./scripts/setup_cluster.sh
    ```

2.  **Verify Nodes**:
    ```bash
    kubectl get nodes
    ```

## ğŸ“‚ Project Structure
```
Cortex5/
â”œâ”€â”€ Architecture/              # Design docs and day-wise plans
â”‚   â”œâ”€â”€ Daywise-Task-Breakdown/
â”‚   â”‚   â”œâ”€â”€ Day1_Agile_Plan.md
â”‚   â”‚   â”œâ”€â”€ Day1_Learnings.md
â”‚   â”‚   â”œâ”€â”€ Day2_Agile_Plan.md
â”‚   â”‚   â””â”€â”€ Day2_Learnings.md
â”‚   â”œâ”€â”€ Architecture.md
â”‚   â”œâ”€â”€ plan.md
â”‚   â””â”€â”€ Vibe_Coding_Plan.md
â”œâ”€â”€ k8s/                       # Kubernetes manifests
â”‚   â””â”€â”€ kind-config.yaml
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ init_db.py            # Database initialization
â”‚   â”œâ”€â”€ ingest_news.py        # News ingestion pipeline
â”‚   â””â”€â”€ setup_cluster.sh      # Kind cluster setup
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/               # Agent implementations
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”œâ”€â”€ data_agent.py     # Market data fetching & storage
â”‚   â”‚   â”œâ”€â”€ sentiment_agent.py # RAG-based sentiment analysis
â”‚   â”‚   â”œâ”€â”€ quant_agent.py    # Technical analysis
â”‚   â”‚   â”œâ”€â”€ risk_agent.py     # Risk validation
â”‚   â”‚   â””â”€â”€ execution_agent.py # Trade logging
â”‚   â”œâ”€â”€ data/                 # Data pipeline components
â”‚   â”‚   â”œâ”€â”€ market_fetcher.py # Yahoo Finance integration
â”‚   â”‚   â”œâ”€â”€ validators.py     # Data validation
â”‚   â”‚   â”œâ”€â”€ db_schema.sql     # TimescaleDB schema
â”‚   â”‚   â”œâ”€â”€ db_client.py      # TimescaleDB client
â”‚   â”‚   â”œâ”€â”€ news_fetcher.py   # News API integration
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # Sentence transformers
â”‚   â”‚   â”œâ”€â”€ vector_schema.py  # Qdrant schemas
â”‚   â”‚   â””â”€â”€ qdrant_client.py  # Qdrant vector store
â”‚   â”œâ”€â”€ utils/                # Utility functions
â”‚   â”‚   â”œâ”€â”€ indicators.py     # Technical indicators (RSI, MACD, etc.)
â”‚   â”‚   â””â”€â”€ risk_manager.py   # Risk management logic
â”‚   â”œâ”€â”€ graph.py              # LangGraph definition
â”‚   â””â”€â”€ state.py              # Global state schema
â”œâ”€â”€ tests/                    # Test suite (planned)
â”œâ”€â”€ .env.example              # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml        # Local infrastructure
â”œâ”€â”€ main.py                   # Entry point
â”œâ”€â”€ pyproject.toml            # Dependencies
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Environment Variables
Key configuration options in `.env`:

```bash
# LLM Configuration
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434

# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=password

# Vector Store
QDRANT_HOST=localhost
QDRANT_PORT=6333

# News API (optional)
NEWS_API_KEY=your_key_here

# Risk Parameters
MAX_POSITION_PCT=0.10      # Max 10% per position
MAX_VOLATILITY=0.03        # Max 3% daily volatility
MIN_SENTIMENT_SCORE=0.5    # Min sentiment for BUY
```

## ğŸ“ˆ Performance

Typical execution times (M1/M2 Mac):
- Market data fetch (30 days): ~1-2s
- News fetch (10 articles): ~2-3s
- Embedding generation (10 articles): ~1-2s
- Vector search (top-5): <100ms
- Full agent pipeline: ~8-12s

## ğŸ§ª Testing

### Manual Testing
```bash
# 1. Start infrastructure
docker-compose up -d

# 2. Initialize database
python scripts/init_db.py

# 3. Ingest sample data
python scripts/ingest_news.py --tickers AAPL --days 7

# 4. Run analysis
python main.py
```

### Verify Data
```bash
# Check TimescaleDB
docker exec -it cortex5-timescaledb psql -U postgres -d postgres -c \
  "SELECT symbol, timestamp, close FROM market_data ORDER BY timestamp DESC LIMIT 5;"

# Check Qdrant (open browser)
open http://localhost:6333/dashboard
```

## ğŸ“š Documentation

- [Day 1 Learnings](Architecture/Daywise-Task-Breakdown/Day1_Learnings.md) - Foundation setup
- [Day 2 Learnings](Architecture/Daywise-Task-Breakdown/Day2_Learnings.md) - Data pipelines & intelligence
- [Architecture Overview](Architecture/Architecture.md) - System design
- [Implementation Plan](Architecture/plan.md) - Technical blueprint

## ğŸ›£ï¸ Roadmap

### Day 3 (Planned)
- [ ] FastAPI backend with WebSocket support
- [ ] Next.js dashboard for monitoring
- [ ] Backtesting framework
- [ ] Performance metrics (Sharpe ratio, drawdown)

### Future
- [ ] Production deployment (AWS EKS)
- [ ] CI/CD pipeline
- [ ] Prometheus + Grafana monitoring
- [ ] Paper trading mode
- [ ] Strategy optimization

## ğŸ¤ Contributing
1.  Fork the repository
2.  Create your feature branch (`git checkout -b feature/amazing-feature`)
3.  Commit your changes (`git commit -m 'Add some amazing feature'`)
4.  Push to the branch (`git push origin feature/amazing-feature`)
5.  Open a Pull Request

## ğŸ“„ License
This project is for educational purposes.

## ğŸ™ Acknowledgments
- LangChain & LangGraph teams
- Ollama for local LLM inference
- TimescaleDB & Qdrant communities
